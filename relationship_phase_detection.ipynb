{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "relationship_phase_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNihNBI3jTZuQNDhSTU62NU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigeek/Visual-Relationship-Detection-LTN/blob/master/relationship_phase_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LHsSYva0hFc4",
        "outputId": "b55c89b8-3d3c-46cd-99d0-10d1580fdaec"
      },
      "source": [
        "!pip install anytree\n",
        "!pip install rdflib\n",
        "!pip install tensorflow==1.15.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anytree\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/65/be23d8c3ecd68d40541d49812cd94ed0f3ee37eb88669ca15df0e43daed1/anytree-2.8.0-py2.py3-none-any.whl (41kB)\n",
            "\r\u001b[K     |███████▉                        | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib) (2.4.7)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.0 rdflib-5.0.0\n",
            "Collecting tensorflow==1.15.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/99abd43185d94adaaaddf8f44a80c418a91977924a7bc39b8dacd0c495b0/tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 81kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.12.1)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.5) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=020138ed4b39a672678d7792eb3fd14d8eec132bc3aa48f190ebb482ec019e5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia5Gm2yAUcD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503ca442-b37a-4094-eba6-04a327042743"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYr-6IVtcPPR",
        "outputId": "be46aed7-6bc1-4714-f914-84cab9db0f31"
      },
      "source": [
        "%cd '/content/drive/MyDrive/tesi/Visual-Relationship-Detection-LTN'\n",
        "\n",
        "# TODO creare script per scaricare dataset e piazzarlo nel posto giusto\n",
        "#!unzip 'data/sg_dataset.zip' -d 'data'\n",
        "\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tesi/Visual-Relationship-Detection-LTN\n",
            "data\t\t\t   refine_predictions.py\n",
            "logictensornetworks.py\t   relationship_phase_detection.ipynb\n",
            "models\t\t\t   relationship_phrase_detection.py\n",
            "predicate_detection.ipynb  train.py\n",
            "predicate_detection.py\t   visual_relationship_dataset.py\n",
            "__pycache__\t\t   Visual-Relationship-Detection-master\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lxyAJv4cZ7n"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ztY4QN0mcy_",
        "outputId": "fb28ef04-5f4a-4539-c3d0-788f0c46f8b0"
      },
      "source": [
        "from visual_relationship_dataset import *\n",
        "import os\n",
        "import scipy.io as sio\n",
        "from PIL import Image\n",
        "import copy\n",
        "from refine_predictions import refine_equiv\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# swith between GPU and CPU\n",
        "config = tf.ConfigProto(device_count={'GPU': 1})\n",
        "\n",
        "img_dir = 'data/sg_dataset/sg_test_images' ###\n",
        "\n",
        "# Load training data for prio statistics on the dataset\n",
        "triples_of_train_data = get_data(\"train\", False)\n",
        "\n",
        "# Computing positive and negative examples for predicates and types\n",
        "#idxs_of_positive_examples_of_predicates = {}\n",
        "\n",
        "#for predicate in selected_predicates:\n",
        "#    idxs_of_positive_examples_of_predicates[predicate] = np.where(predicates[triples_of_train_data[:, -2]] == predicate)[0]\n",
        "\n",
        "#prior_stats = np.array([len(idxs_of_positive_examples_of_predicates[pred]) for pred in selected_predicates])\n",
        "#prior_freq = np.true_divide(prior_stats, np.sum(prior_stats))\n",
        "\n",
        "sum_predicates = len(triples_of_train_data[:, -2])\n",
        "predicates_annotations = triples_of_train_data[:, -2]\n",
        "from collections import Counter\n",
        "counter_values = Counter(predicates_annotations).values()\n",
        "\n",
        "prior_freq = np.zeros(70)\n",
        "for i, value in enumerate(counter_values):\n",
        "  prior_freq[i] = value / sum_predicates\n",
        "\n",
        "image_path = sio.loadmat('Visual-Relationship-Detection-master/data/imagePath.mat')\n",
        "object_detection = sio.loadmat('Visual-Relationship-Detection-master/data/objectDetRCNN.mat')\n",
        "detection_bboxes = object_detection['detection_bboxes']\n",
        "detection_labels = object_detection['detection_labels']\n",
        "detection_confs = object_detection['detection_confs']\n",
        "\n",
        "for img_id in range(len(detection_bboxes[0])):\n",
        "    if len(detection_bboxes[0][img_id]) > 0:\n",
        "        assert np.all(detection_bboxes[0][img_id][:, 0] < detection_bboxes[0][img_id][:, 2])\n",
        "        assert np.all(detection_bboxes[0][img_id][:, 1] < detection_bboxes[0][img_id][:, 3])\n",
        "\n",
        "features_detected_bb = []\n",
        "obj_bboxes_ours = []\n",
        "sub_bboxes_ours = []\n",
        "obj_labels_ours = []\n",
        "sub_labels_ours = []\n",
        "\n",
        "semantic_feat_vect = np.zeros(len(types))\n",
        "\n",
        "for pic_idx in range(detection_bboxes.shape[1]):\n",
        "    detection_bboxes[0, pic_idx] = detection_bboxes[0, pic_idx].astype(np.float)\n",
        "    features_per_image = np.empty((0, 2*number_of_features + number_of_extra_features))\n",
        "    obj_bboxes_ours_per_image = np.array([]).reshape(0, 4)\n",
        "    sub_bboxes_ours_per_image = np.array([]).reshape(0, 4)\n",
        "    obj_label_per_image = np.array([])\n",
        "    sub_label_per_image = np.array([])\n",
        "\n",
        "    # normalize data\n",
        "    if len(detection_bboxes[0, pic_idx]) > 0:\n",
        "        img = Image.open(os.path.join(img_dir, image_path['imagePath'][0, pic_idx][0]).replace('png', 'jpg'))\n",
        "        width, height = img.size\n",
        "        normalized_detection_bboxes = copy.deepcopy(detection_bboxes)\n",
        "        copy.deepcopy\n",
        "        normalized_detection_bboxes[0, pic_idx][:, -4] /= width\n",
        "        normalized_detection_bboxes[0, pic_idx][:, -3] /= height\n",
        "        normalized_detection_bboxes[0, pic_idx][:, -2] /= width\n",
        "        normalized_detection_bboxes[0, pic_idx][:, -1] /= height\n",
        "\n",
        "    for bb1_idx in range(len(detection_bboxes[0, pic_idx])):\n",
        "        for bb2_idx in range(len(detection_bboxes[0, pic_idx])):\n",
        "            if bb1_idx != bb2_idx:\n",
        "                bb1 = normalized_detection_bboxes[0, pic_idx][bb1_idx]\n",
        "                bb2 = normalized_detection_bboxes[0, pic_idx][bb2_idx]\n",
        "                sub_label_per_image = np.append(sub_label_per_image, detection_labels[0, pic_idx][bb1_idx, 0])\n",
        "                obj_label_per_image = np.append(obj_label_per_image, detection_labels[0, pic_idx][bb2_idx, 0])\n",
        "\n",
        "                feat_vect_bb1 = np.hstack((semantic_feat_vect, bb1))\n",
        "                feat_vect_bb2 = np.hstack((semantic_feat_vect, bb2))\n",
        "                feat_vect_bb1[detection_labels[0, pic_idx][bb1_idx]] = detection_confs[0, pic_idx][bb1_idx]\n",
        "                feat_vect_bb2[detection_labels[0, pic_idx][bb2_idx]] = detection_confs[0, pic_idx][bb2_idx]\n",
        "                feat_vec_pair = np.hstack((feat_vect_bb1, feat_vect_bb2, computing_extended_features(bb1, bb2)))\n",
        "\n",
        "                features_per_image = np.vstack((features_per_image, feat_vec_pair[np.newaxis, :]))\n",
        "                sub_bboxes_ours_per_image = np.vstack((sub_bboxes_ours_per_image, detection_bboxes[0, pic_idx][bb1_idx]))\n",
        "                obj_bboxes_ours_per_image = np.vstack((obj_bboxes_ours_per_image, detection_bboxes[0, pic_idx][bb2_idx]))\n",
        "\n",
        "    features_detected_bb.append(features_per_image)\n",
        "    obj_bboxes_ours.append(obj_bboxes_ours_per_image)\n",
        "    sub_bboxes_ours.append(sub_bboxes_ours_per_image)\n",
        "    obj_labels_ours.append(obj_label_per_image)\n",
        "    sub_labels_ours.append(sub_label_per_image)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of loading data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXot7SbGm6cu",
        "outputId": "1332b30f-4ba8-4146-e91e-037cc045bba1"
      },
      "source": [
        "model_list = [\n",
        "    \"models/KB_wc_2500.ckpt\",\n",
        "    \"models/KB_nc_2500.ckpt\"]\n",
        "\n",
        "for model_type in model_list:\n",
        "\n",
        "    model = model_type\n",
        "    obj_bboxes_ours_output = []\n",
        "    sub_bboxes_ours_output = []\n",
        "    model_label = model.split(\"/\")[-1][:-5]\n",
        "    print(model.upper())\n",
        "    predicted_predicates_values_tensor = tf.concat([isInRelation[predicate].tensor() for predicate in selected_predicates], 1)\n",
        "    # concat edited, axis was in the wrong placesaver = tf.train.Saver()\n",
        "    saver = tf.train.Saver()\n",
        "    sess = tf.Session(config=config)\n",
        "    saver.restore(sess, model)\n",
        "    rlp_confs_ours = []\n",
        "    rlp_labels_ours = []\n",
        "\n",
        "    for pic_idx in range(detection_bboxes.shape[1]):\n",
        "        if pic_idx % 100 == 0:\n",
        "            print (\"Eval img\" + str(pic_idx))\n",
        "        values_of_predicates = np.array([], dtype=np.float32).reshape(0, 70)\n",
        "        values_of_predicates = sess.run(predicted_predicates_values_tensor, {pairs_of_objects.tensor: features_detected_bb[pic_idx]})\n",
        "\n",
        "        values_of_predicates = refine_equiv(values_of_predicates, selected_predicates, \"max\")\n",
        "        values_of_predicates = np.multiply(values_of_predicates, prior_freq)\n",
        "\n",
        "        conf_predicates_per_image = values_of_predicates.flatten('F')\n",
        "        sub_bboxes_ours_output.append(np.tile(sub_bboxes_ours[pic_idx], (len(selected_predicates), 1)))\n",
        "        obj_bboxes_ours_output.append(np.tile(obj_bboxes_ours[pic_idx], (len(selected_predicates), 1)))\n",
        "        label_predicates_per_image = np.hstack(\n",
        "            (np.tile(sub_labels_ours[pic_idx], len(selected_predicates))[:, np.newaxis],\n",
        "             np.repeat(np.array(range(1, len(selected_predicates) + 1)), len(features_detected_bb[pic_idx]))[:,\n",
        "             np.newaxis],\n",
        "             np.tile(obj_labels_ours[pic_idx], len(selected_predicates))[:, np.newaxis]))\n",
        "\n",
        "        rlp_confs_ours.append(conf_predicates_per_image[:, np.newaxis])\n",
        "        rlp_labels_ours.append(label_predicates_per_image)\n",
        "\n",
        "    sess.close()\n",
        "\n",
        "\n",
        "    ### to do\n",
        "    sio.savemat(\"Visual-Relationship-Detection-master/results_LTN/relationship_det_result_\" + model_label + \".mat\",\n",
        "                {'sub_bboxes_ours': sub_bboxes_ours_output,\n",
        "                 'obj_bboxes_ours': obj_bboxes_ours_output,\n",
        "                 'rlp_confs_ours': rlp_confs_ours,\n",
        "                 'rlp_labels_ours': rlp_labels_ours})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELS/KB_WC_2500.CKPT\n",
            "INFO:tensorflow:Restoring parameters from models/KB_wc_2500.ckpt\n",
            "Eval img0\n",
            "Eval img100\n",
            "Eval img200\n",
            "Eval img300\n",
            "Eval img400\n",
            "Eval img500\n",
            "Eval img600\n",
            "Eval img700\n",
            "Eval img800\n",
            "Eval img900\n",
            "MODELS/KB_NC_2500.CKPT\n",
            "INFO:tensorflow:Restoring parameters from models/KB_nc_2500.ckpt\n",
            "Eval img0\n",
            "Eval img100\n",
            "Eval img200\n",
            "Eval img300\n",
            "Eval img400\n",
            "Eval img500\n",
            "Eval img600\n",
            "Eval img700\n",
            "Eval img800\n",
            "Eval img900\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}